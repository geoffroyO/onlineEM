{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "81df61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmm.gmm_jax import GMM as GMM_jax\n",
    "\n",
    "import jax\n",
    "from jax import vmap, jit\n",
    "import jax.numpy as jnp\n",
    "from jax.lax import fori_loop\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "\n",
    "def batch_data(X, batch_size):\n",
    "    N, _ = X.shape\n",
    "    X_batch = []\n",
    "    for k in range(N // batch_size):\n",
    "        X_batch.append(jnp.array(X[k * batch_size:(k + 1) * batch_size]))\n",
    "    if (N // batch_size) * batch_size != len(X):\n",
    "        X_batch.append(jnp.array(X[(N // batch_size) * batch_size:]))\n",
    "    return X_batch\n",
    "\n",
    "@jit\n",
    "def update_s01(y, t, s0, s1, gam):\n",
    "    s0 = gam * t + (1 - gam) * s0\n",
    "    s1 = gam * jnp.einsum('i,k->ik', t, y) + (1 - gam) * s1\n",
    "    return s0, s1\n",
    "\n",
    "@jit\n",
    "def init_S2(y, t, inv_S2, log_det_inv_S2, gam, batch_size):\n",
    "    S2y = jnp.einsum('kij,j->ki', inv_S2, y)\n",
    "    square_S2y = jnp.einsum('ki,kj->kij', S2y, S2y)\n",
    "\n",
    "    t_square_S2y = jnp.einsum('k,kij->kij', t, square_S2y)\n",
    "    yS2y = jnp.einsum('j,kj->k', y, S2y)\n",
    "    t_yS2y = t * yS2y\n",
    "    \n",
    "    tmp_den = 1 + gam * t_yS2y / (batch_size * (1 - gam))\n",
    "    tmp_num = gam * t_square_S2y / (batch_size * (1 - gam) ** 2)\n",
    "    tmp = tmp_num / tmp_den[:, jnp.newaxis, jnp.newaxis]\n",
    "\n",
    "    inv_S2 = inv_S2 / (1 - gam) - tmp\n",
    "    \n",
    "    tmp = -jnp.log(1 + gam * t_yS2y / (batch_size * (1 - gam)))\n",
    "    tmp -= len(y) * jnp.log(1 - gam)\n",
    "    log_det_inv_S2 = tmp + log_det_inv_S2\n",
    "    \n",
    "    return inv_S2, log_det_inv_S2\n",
    "\n",
    "@jit\n",
    "def update_S2(i, val):\n",
    "    y_batch, t_batch, inv_S2, log_det_inv_S2, gam, batch_size = val\n",
    "    y, t = jnp.take(y_batch, i, axis=0), jnp.take(t_batch, i, axis=0)\n",
    "    S2y = jnp.einsum('kij,j->ki', inv_S2, y)\n",
    "    square_S2y = jnp.einsum('ki,kj->kij', S2y, S2y)\n",
    "\n",
    "    t_square_S2y = jnp.einsum('k,kij->kij', t, square_S2y)\n",
    "    yS2y = jnp.einsum('j,kj->k', y, S2y)\n",
    "    t_yS2y = t * yS2y\n",
    "\n",
    "    tmp_den = 1 + gam * t_yS2y / batch_size\n",
    "    tmp_num = gam * t_square_S2y / batch_size\n",
    "    tmp = tmp_num / tmp_den[:, jnp.newaxis, jnp.newaxis]\n",
    "\n",
    "    inv_S2 = inv_S2 - tmp\n",
    "\n",
    "    ### log det inv S2 ###\n",
    "    tmp = -jnp.log(1 + gam * t_yS2y / batch_size)\n",
    "    log_det_inv_S2 = tmp + log_det_inv_S2\n",
    "\n",
    "    return y_batch, t_batch, inv_S2, log_det_inv_S2, gam, batch_size\n",
    "\n",
    "@jit\n",
    "def _update_pi(s0):\n",
    "    return s0 / s0.sum()\n",
    "\n",
    "@jit\n",
    "def _update_mu(s0, s1):\n",
    "    return s1 / s0[:, jnp.newaxis]\n",
    "\n",
    "@jit\n",
    "def _update_prec(s0, s1, inv_S2, log_det_inv_S2):\n",
    "    S2s1 = jnp.einsum('kij,kj->ki', inv_S2, s1)\n",
    "    square_S2s1 = jnp.einsum('ki,kj->kij', S2s1, S2s1)\n",
    "\n",
    "    s1S2s1 = jnp.einsum('kj,kj->k', s1, S2s1)\n",
    "    s0_s1S2s1 = 1 - s1S2s1 / s0\n",
    "\n",
    "    tmp = square_S2s1 / s0_s1S2s1[:, jnp.newaxis, jnp.newaxis]\n",
    "\n",
    "    s0S2 = jnp.einsum('k,kij->kij', s0, inv_S2)\n",
    "    prec = s0S2 + tmp\n",
    "\n",
    "    log_det_prec = inv_S2.shape[1] * jnp.log(s0)\n",
    "    log_det_prec -= jnp.log(s0_s1S2s1)\n",
    "    log_det_prec += log_det_inv_S2\n",
    "\n",
    "    return prec, log_det_prec\n",
    "\n",
    "class GMMOEM:\n",
    "    def __init__(self, n_components, random_state=42):\n",
    "        self.n_components = n_components\n",
    "        self.pi, self.mu, self.prec, self.log_det_prec = None, None, None, None\n",
    "        self.s0, self.s1, self.inv_S2, self.log_det_inv_S2 = None, None, None, None\n",
    "        \n",
    "    def _initialization(self, X, n_first=1000):\n",
    "        gmm = GaussianMixture(n_components, max_iter=1)\n",
    "        gmm.fit(X[:n_first])\n",
    "        \n",
    "        self.pi = jnp.array(gmm.weights_)\n",
    "        self.mu = jnp.array(gmm.means_)\n",
    "        self.prec = jnp.array(gmm.precisions_)\n",
    "        self.log_det_prec = jnp.log(jnp.linalg.det(self.prec))\n",
    "\n",
    "    \n",
    "    def fit(self, X, batch_size):\n",
    "        self._initialization(X)\n",
    "        gamma = iter((1 - 10e-10) * np.array([k for k in range(2, 10 * 2 * (len(X) // batch_size + 1) + 2)]) ** (-6 / 10))\n",
    "        n_comp, n_features = self.mu.shape\n",
    "        \n",
    "        X_batch = batch_data(X, batch_size)\n",
    "        del X\n",
    "        \n",
    "        self.s0 = jnp.zeros(n_comp)\n",
    "        self.s1 = jnp.zeros(self.mu.shape)\n",
    "        self.inv_S2 = jnp.stack([jnp.diag(jnp.ones(n_features))]*n_comp)\n",
    "        self.log_det_inv_S2 = jnp.log(jnp.linalg.det(self.inv_S2))\n",
    "        \n",
    "        # vmap\n",
    "        _update_s01 = vmap(update_s01, in_axes=(0, 0, None, None, None))\n",
    "        \n",
    "        # Warm-up\n",
    "        posterior = jit(vmap(GMM_jax(self.pi, self.mu, self.prec, self.log_det_prec).posterior))\n",
    "        print('Warm-up...')\n",
    "        for batch in tqdm(X_batch[:200]):\n",
    "            gam = next(gamma)\n",
    "            t = posterior(batch)\n",
    "            s0, s1 = _update_s01(batch, t, self.s0, self.s1, gam)\n",
    "            self.s0 = s0.mean(axis=0)\n",
    "            self.s1 = s1.mean(axis=0)\n",
    "            inv_S2, log_det_inv_S2 = init_S2(jnp.take(batch, 0, axis=0), jnp.take(t, 0, axis=0), self.inv_S2, self.log_det_inv_S2, gam, batch_size)\n",
    "            lower, upper = 1, batch_size\n",
    "            val = (batch, t, inv_S2, log_det_inv_S2, gam, batch_size)\n",
    "            _, _, self.inv_S2, self.log_det_inv_S2, _, _ = fori_loop(lower, upper, update_S2, val)\n",
    "        \n",
    "        print('Training...')\n",
    "        for batch in tqdm(X_batch[200:]):\n",
    "            posterior = jit(vmap(GMM_jax(self.pi, self.mu, self.prec, self.log_det_prec).posterior))\n",
    "            t = posterior(batch)\n",
    "            gam = next(gamma)\n",
    "            \n",
    "            s0, s1 = _update_s01(batch, t, self.s0, self.s1, gam)\n",
    "            self.s0 = s0.mean(axis=0)\n",
    "            self.s1 = s1.mean(axis=0)\n",
    "            inv_S2, log_det_inv_S2 = init_S2(jnp.take(batch, 0, axis=0), jnp.take(t, 0, axis=0), self.inv_S2, self.log_det_inv_S2, gam, batch_size)\n",
    "            lower, upper = 1, batch_size\n",
    "            val = (batch, t, inv_S2, log_det_inv_S2, gam, batch_size)\n",
    "            _, _, self.inv_S2, self.log_det_inv_S2, _, _ = fori_loop(lower, upper, update_S2, val)\n",
    "            \n",
    "            self.pi = _update_pi(self.s0)\n",
    "            self.mu = _update_mu(self.s0, self.s1)\n",
    "            self.inv_S2, self.log_det_inv_S2 = _update_prec(self.s0, self.s1, self.inv_S2, self.log_det_inv_S2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb560797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoffroy/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/mixture/_base.py:282: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm-up...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 233.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 191/191 [00:25<00:00,  7.43it/s]\n"
     ]
    }
   ],
   "source": [
    "n_components = 5\n",
    "batch_size = 256\n",
    "n_first = 1000\n",
    "X = np.random.normal(size=(100000, 10))\n",
    "\n",
    "gmm = GMMOEM(n_components)\n",
    "gmm.fit(X, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
